"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[4071],{7436:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>g,frontMatter:()=>i,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"module-1/bridging-python-agents-to-ros2","title":"Bridging Python Agents to ROS 2 Controllers with rclpy","description":"The Nexus of AI and Robotics","source":"@site/docs/module-1/bridging-python-agents-to-ros2.md","sourceDirName":"module-1","slug":"/module-1/bridging-python-agents-to-ros2","permalink":"/docs/module-1/bridging-python-agents-to-ros2","draft":false,"unlisted":false,"editUrl":"https://github.com/SyedAbdulSami1/Physical-AI-Humanoid-Robotics-Textbook/tree/main/docs/module-1/bridging-python-agents-to-ros2.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"ROS 2 Fundamentals: Nodes, Topics, and Services","permalink":"/docs/module-1/ros2-nodes-topics-services"},"next":{"title":"Understanding URDF for Humanoid Robots: Anatomy of a Digital Body","permalink":"/docs/module-1/urdf-for-humanoids"}}');var o=s(4848),t=s(8453);const i={},a="Bridging Python Agents to ROS 2 Controllers with rclpy",l={},c=[{value:"The Nexus of AI and Robotics",id:"the-nexus-of-ai-and-robotics",level:2},{value:"Understanding <code>rclpy</code>: The Pythonic Interface to ROS 2",id:"understanding-rclpy-the-pythonic-interface-to-ros-2",level:2},{value:"Key Integration Patterns",id:"key-integration-patterns",level:2},{value:"Lab 2.1: Python AI Agent for Simple Obstacle Avoidance (Publisher)",id:"lab-21-python-ai-agent-for-simple-obstacle-avoidance-publisher",level:3},{value:"Lab 2.2: Python Agent for High-Level Task Orchestration (Action Client)",id:"lab-22-python-agent-for-high-level-task-orchestration-action-client",level:2},{value:"Lab 2.3: Python Agent for Joint Position Control (Publisher/Service Client)",id:"lab-23-python-agent-for-joint-position-control-publisherservice-client",level:2},{value:"Python AI for Perception (Subscriber/Publisher)",id:"python-ai-for-perception-subscriberpublisher",level:2},{value:"Common Pitfalls and Solutions for Python-ROS 2 Integration",id:"common-pitfalls-and-solutions-for-python-ros-2-integration",level:2},{value:"Student Exercises (with Hidden Solutions)",id:"student-exercises-with-hidden-solutions",level:2},{value:"Further Reading and Official Resources",id:"further-reading-and-official-resources",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components},{Details:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsxs)(n.h1,{id:"bridging-python-agents-to-ros-2-controllers-with-rclpy",children:["Bridging Python Agents to ROS 2 Controllers with ",(0,o.jsx)(n.code,{children:"rclpy"})]})}),"\n",(0,o.jsx)(n.h2,{id:"the-nexus-of-ai-and-robotics",children:"The Nexus of AI and Robotics"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"rclpy"}),", the Python client library for ROS 2, forms a critical bridge connecting intelligent Python-based AI agents with robust robot control systems. This chapter explores practical patterns for integrating these agents with ROS 2, enabling AI algorithms to perceive robot states, issue commands, and interact with the physical world through ROS 2 controllers. We will focus on common scenarios in humanoid robotics like high-level task planning, perception processing, and dynamic control."]}),"\n",(0,o.jsxs)(n.h2,{id:"understanding-rclpy-the-pythonic-interface-to-ros-2",children:["Understanding ",(0,o.jsx)(n.code,{children:"rclpy"}),": The Pythonic Interface to ROS 2"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.code,{children:"rclpy"})," is the official Python API for ROS 2. It provides all the necessary functionalities to create ROS 2 nodes, publish and subscribe to topics, call and provide services, and interact with actions, all within a familiar Pythonic syntax. Its design emphasizes ease of use for rapid prototyping and development, while still offering the performance benefits of ROS 2's underlying C++ core (RCL)."]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-mermaid",children:"graph TD\n    subgraph Python AI Agent\n        A[AI Algorithm (TensorFlow/PyTorch)]\n        B[Perception Logic (OpenCV)]\n        C[Decision Making (LLM/Planning)]\n        D[rclpy Node (Python)]\n    end\n\n    subgraph ROS 2 Ecosystem\n        E[ROS 2 Topic: /joint_states] -- Data Flow --\x3e D\n        F[ROS 2 Topic: /cmd_vel] <-- Command Flow -- D\n        G[ROS 2 Service: /robot_mode] <-- Service Call -- D\n        H[ROS 2 Action: /navigate_to_pose] <-- Action Goal -- D\n        I[ROS 2 Controller (C++/hardware)]\n        J[Sensors (Lidar/Camera)]\n    end\n\n    A -- Calls D.publish() --\x3e F\n    B -- Calls D.subscribe() --\x3e E\n    C -- Calls D.call_service() --\x3e G\n    C -- Calls D.send_goal() --\x3e H\n    F --\x3e I\n    E <-- J\n"})}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsxs)(n.em,{children:["Figure 2.1: Bridging Python AI agents to ROS 2 controllers via ",(0,o.jsx)(n.code,{children:"rclpy"}),"."]})}),"\n",(0,o.jsx)(n.h2,{id:"key-integration-patterns",children:"Key Integration Patterns"}),"\n",(0,o.jsx)(n.p,{children:"Integrating Python AI agents with ROS 2 typically involves one or more of the following patterns:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Sensor Data Processing (Subscriber)"}),": Python agents subscribe to sensor topics, process raw data (e.g., image recognition, point cloud segmentation), and potentially publish processed results."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Command Generation (Publisher)"}),": Python agents generate high-level or low-level commands (e.g., velocity commands, joint trajectories) and publish them to controller topics."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Task Orchestration (Service/Action Client)"}),": Python agents act as clients to trigger specific, discrete robot behaviors (services) or manage long-running tasks with feedback (actions)."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Configuration/State Management (Service Server)"}),": Python agents can expose their internal state or configuration parameters via ROS 2 services, allowing other nodes to query or modify them."]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"lab-21-python-ai-agent-for-simple-obstacle-avoidance-publisher",children:"Lab 2.1: Python AI Agent for Simple Obstacle Avoidance (Publisher)"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Create a new Python package (if not already done)"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws/src\nros2 pkg create --build-type ament_python simple_avoidance_agent --dependencies rclpy geometry_msgs sensor_msgs\ncd simple_avoidance_agent/simple_avoidance_agent\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["Create ",(0,o.jsx)(n.code,{children:"avoidance_agent.py"})]}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist # For velocity commands\nfrom sensor_msgs.msg import LaserScan # For LiDAR data\n\nclass AvoidanceAgent(Node):\n    def __init__(self):\n        super().__init__('avoidance_agent')\n        self.publisher_ = self.create_publisher(Twist, '/cmd_vel', 10)\n        self.subscription = self.create_subscription(\n            LaserScan,\n            '/scan', # Assuming your robot publishes LiDAR data on /scan\n            self.scan_callback,\n            10)\n        self.subscription  # prevent unused variable warning\n        self.get_logger().info('Avoidance Agent has started, waiting for scan data...')\n\n        self.linear_speed = 0.2  # m/s\n        self.angular_speed = 0.5 # rad/s\n\n    def scan_callback(self, msg):\n        # Very simple obstacle detection logic: check front-left, front, front-right sectors\n        # LiDAR scan_ranges is typically 0 to 359 degrees, with 0 being straight ahead.\n        # Adjust indices based on your LiDAR's angular resolution and range.\n        num_ranges = len(msg.ranges)\n        if num_ranges == 0:\n            return\n\n        # Example for a 360-degree LiDAR, adjust if your LiDAR is different (e.g., 180 degrees)\n        # Front sector: ~ (-15 to +15 degrees)\n        front_idx = range(0, 15)\n        front_idx_alt = range(num_ranges - 15, num_ranges) # For wrap-around\n\n        # Filter out 'inf' (no detection) and 'nan' (invalid data)\n        valid_ranges = [r for r in msg.ranges if r > msg.range_min and r < msg.range_max]\n\n        if not valid_ranges:\n            return # No valid obstacle data\n\n        # Check a small sector in front\n        threshold_distance = 0.7 # meters\n\n        front_danger = False\n        for i in front_idx:\n            if msg.ranges[i] < threshold_distance:\n                front_danger = True\n                break\n        for i in front_idx_alt:\n            if msg.ranges[i] < threshold_distance:\n                front_danger = True\n                break\n\n        twist_msg = Twist()\n        if front_danger:\n            twist_msg.linear.x = 0.0\n            twist_msg.angular.z = self.angular_speed # Turn right to avoid\n            self.get_logger().warn('Obstacle detected! Turning right.')\n        else:\n            twist_msg.linear.x = self.linear_speed # Move forward\n            twist_msg.angular.z = 0.0\n            self.get_logger().info('Path clear, moving forward.')\n\n        self.publisher_.publish(twist_msg)\n\ndef main(args=None):\n    rclpy.init(args=args)\n    avoidance_agent = AvoidanceAgent()\n    try:\n        rclpy.spin(avoidance_agent)\n    except KeyboardInterrupt:\n        pass\n    avoidance_agent.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["Update ",(0,o.jsx)(n.code,{children:"setup.py"})]}),":\nAdd the entry point in ",(0,o.jsx)(n.code,{children:"~/ros2_ws/src/simple_avoidance_agent/setup.py"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"entry_points={\n    'console_scripts': [\n        'avoidance_agent = simple_avoidance_agent.avoidance_agent:main',\n    ],\n},\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Build and Source"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws\ncolcon build\nsource install/setup.bash\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Run Simulation and Agent"}),":","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Terminal 1 (Start Gazebo with a robot):","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"ros2 launch turtlebot3_gazebo turtlebot3_world.launch.py\n# You might need to manually spawn a turtlebot3_waffle or similar if it's not default\n# ros2 run gazebo_ros spawn_entity.py -entity turtlebot3_waffle -file $(ros2 pkg prefix turtlebot3_description)/share/turtlebot3_description/urdf/turtlebot3_waffle.urdf -x 0 -y 0 -z 0.1\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Terminal 2 (Run your Python agent):","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"ros2 run simple_avoidance_agent avoidance_agent\n"})}),"\n"]}),"\n"]}),"\n","Observe the robot moving forward and turning when it detects an obstacle in Gazebo."]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Common Pitfall"}),": Incorrect topic names or message types, leading to the agent not receiving data or the robot not responding.\n",(0,o.jsx)(n.strong,{children:"Fix"}),": Use ",(0,o.jsx)(n.code,{children:"ros2 topic list -t"})," and ",(0,o.jsx)(n.code,{children:"ros2 topic info /scan"})," (or ",(0,o.jsx)(n.code,{children:"/cmd_vel"}),") to verify."]}),"\n",(0,o.jsx)(n.h2,{id:"lab-22-python-agent-for-high-level-task-orchestration-action-client",children:"Lab 2.2: Python Agent for High-Level Task Orchestration (Action Client)"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Create a new Python package (if not already done)"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws/src\nros2 pkg create --build-type ament_python nav_agent --dependencies rclpy nav2_msgs geometry_msgs\ncd nav_agent/nav_agent\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["Create ",(0,o.jsx)(n.code,{children:"nav_commander.py"})]}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.action import ActionClient\nfrom rclpy.node import Node\nfrom nav2_msgs.action import NavigateToPose # Nav2's action type\nfrom geometry_msgs.msg import PoseStamped # For sending a target pose\n\nclass NavCommander(Node):\n    def __init__(self):\n        super().__init__('nav_commander')\n        self._action_client = ActionClient(self, NavigateToPose, 'navigate_to_pose')\n        self.get_logger().info('Navigation Commander agent started.')\n\n    def send_goal(self, x, y, yaw_degrees):\n        self.get_logger().info('Waiting for Nav2 action server...')\n        self._action_client.wait_for_server()\n\n        goal_msg = NavigateToPose.Goal()\n        goal_msg.pose.header.frame_id = 'map' # Usually 'map' frame for navigation goals\n        goal_msg.pose.header.stamp = self.get_clock().now().to_msg()\n        goal_msg.pose.pose.position.x = x\n        goal_msg.pose.pose.position.y = y\n        goal_msg.pose.pose.orientation.z = self.degrees_to_quaternion_z(yaw_degrees)\n        goal_msg.pose.pose.orientation.w = self.degrees_to_quaternion_w(yaw_degrees)\n\n        self.get_logger().info(f'Sending navigation goal: x={x}, y={y}, yaw={yaw_degrees} degrees')\n        self._send_goal_future = self._action_client.send_goal_async(\n            goal_msg,\n            feedback_callback=self.feedback_callback\n        )\n\n        self._send_goal_future.add_done_callback(self.goal_response_callback)\n\n    def degrees_to_quaternion_z(self, degrees):\n        import math\n        return math.sin(math.radians(degrees) / 2)\n\n    def degrees_to_quaternion_w(self, degrees):\n        import math\n        return math.cos(math.radians(degrees) / 2)\n\n    def goal_response_callback(self, future):\n        goal_handle = future.result()\n        if not goal_handle.accepted:\n            self.get_logger().error('Goal rejected by Nav2 server :(')\n            return\n\n        self.get_logger().info('Goal accepted by Nav2 server :)')\n        self._get_result_future = goal_handle.get_result_async()\n        self._get_result_future.add_done_callback(self.get_result_callback)\n\n    def get_result_callback(self, future):\n        status = future.result().status\n        if status == ActionClient.GoalStatus.STATUS_SUCCEEDED:\n            self.get_logger().info('Navigation Goal succeeded!')\n        else:\n            self.get_logger().warn(f'Navigation Goal failed with status: {status}')\n        rclpy.shutdown()\n\n    def feedback_callback(self, feedback_msg):\n        # Nav2 provides detailed feedback, including current pose, distance remaining, etc.\n        current_pose = feedback_msg.current_pose.pose.position\n        distance_remaining = feedback_msg.distance_remaining\n        self.get_logger().info(f'Feedback: Current Pose (x={current_pose.x:.2f}, y={current_pose.y:.2f}), '\n                               f'Distance Remaining: {distance_remaining:.2f}m')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    nav_commander = NavCommander()\n    # Example goal: Go to x=2.0, y=1.5, facing 90 degrees (North)\n    nav_commander.send_goal(2.0, 1.5, 90.0)\n    rclpy.spin(nav_commander)\n\nif __name__ == '__main__':\n    main()\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["Update ",(0,o.jsx)(n.code,{children:"setup.py"})]}),":\nAdd the entry point in ",(0,o.jsx)(n.code,{children:"~/ros2_ws/src/nav_agent/setup.py"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"entry_points={\n    'console_scripts': [\n        'nav_commander = nav_agent.nav_commander:main',\n    ],\n},\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Build and Source"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws\ncolcon build\nsource install/setup.bash\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Run Nav2 Simulation and Agent"}),":","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Terminal 1 (Start Nav2 with a robot, e.g., TurtleBot3):","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# Example for TurtleBot3\nexport TURTLEBOT3_MODEL=waffle_pi # or burger\nros2 launch turtlebot3_navigation2 navigation2.launch.py use_sim_time:=True map:=/path/to/your/map.yaml\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Terminal 2 (Run your Python agent):","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"ros2 run nav_agent nav_commander\n"})}),"\n"]}),"\n"]}),"\n","Observe the robot navigating to the specified pose in the simulation, with feedback logged by your agent."]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Common Pitfall"}),": Nav2 setup can be complex. Ensure your map is correctly loaded, localization (AMCL) is running, and the ",(0,o.jsx)(n.code,{children:"navigate_to_pose"})," action server is active.\n",(0,o.jsx)(n.strong,{children:"Fix"}),": Debug Nav2 components separately before running the agent. Use ",(0,o.jsx)(n.code,{children:"ros2 action list"})," to verify ",(0,o.jsx)(n.code,{children:"navigate_to_pose"})," is available."]}),"\n",(0,o.jsx)(n.h2,{id:"lab-23-python-agent-for-joint-position-control-publisherservice-client",children:"Lab 2.3: Python Agent for Joint Position Control (Publisher/Service Client)"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Create a new Python package"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws/src\nros2 pkg create --build-type ament_python joint_controller_agent --dependencies rclpy trajectory_msgs std_srvs\ncd joint_controller_agent/joint_controller_agent\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["Create ",(0,o.jsx)(n.code,{children:"humanoid_joint_controller.py"})]}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom trajectory_msgs.msg import JointTrajectory, JointTrajectoryPoint # For joint commands\nfrom std_srvs.srv import Trigger # For homing service\n\nclass HumanoidJointController(Node):\n    def __init__(self):\n        super().__init__('humanoid_joint_controller')\n        self.joint_publisher = self.create_publisher(JointTrajectory, '/joint_trajectory_controller/joint_trajectory', 10)\n        self.home_client = self.create_client(Trigger, '/robot_home_service') # Custom service to home robot (assumed)\n\n        # Define joint names (replace with actual joint names from your humanoid's URDF)\n        self.joint_names = [\n            'left_shoulder_joint', 'left_elbow_joint',\n            'right_shoulder_joint', 'right_elbow_joint',\n            'left_hip_joint', 'left_knee_joint', 'left_ankle_joint',\n            'right_hip_joint', 'right_knee_joint', 'right_ankle_joint'\n            # Add more joints as per your robot's URDF\n        ]\n        self.get_logger().info('Humanoid Joint Controller agent started.')\n\n    def send_joint_command(self, positions, time_from_start_sec=1.0):\n        if len(positions) != len(self.joint_names):\n            self.get_logger().error('Number of positions must match number of joints.')\n            return\n\n        msg = JointTrajectory()\n        msg.header.stamp = self.get_clock().now().to_msg()\n        msg.joint_names = self.joint_names\n\n        point = JointTrajectoryPoint()\n        point.positions = [float(p) for p in positions] # Ensure floats\n        point.time_from_start.sec = int(time_from_start_sec)\n        point.time_from_start.nanosec = int((time_from_start_sec - int(time_from_start_sec)) * 1e9)\n        msg.points.append(point)\n\n        self.joint_publisher.publish(msg)\n        self.get_logger().info(f'Sent joint command: {positions}')\n\n    def call_home_service(self):\n        if not self.home_client.wait_for_service(timeout_sec=1.0):\n            self.get_logger().warn('Home service not available.')\n            return False\n\n        request = Trigger.Request()\n        future = self.home_client.call_async(request)\n        rclpy.spin_until_future_complete(self, future)\n\n        if future.result() is not None:\n            self.get_logger().info(f'Home service response: {future.result().success}, {future.result().message}')\n            return future.result().success\n        else:\n            self.get_logger().error('Home service call failed.')\n            return False\n\ndef main(args=None):\n    rclpy.init(args=args)\n    controller = HumanoidJointController()\n\n    # Example: Move to a specific pose (e.g., 'neutral' pose)\n    controller.get_logger().info('Moving robot to a neutral pose.')\n    neutral_positions = [0.0] * len(controller.joint_names) # All joints to 0.0 radians\n    controller.send_joint_command(neutral_positions, time_from_start_sec=2.0)\n    rclpy.spin_once(controller, timeout_sec=2.5) # Allow time for command to be processed\n\n    # Example: Call a homing service (if available)\n    controller.get_logger().info('Calling home service...')\n    controller.call_home_service()\n    rclpy.spin_once(controller, timeout_sec=1.0)\n\n    # Example: Move to a 'waving' pose (adjust positions for your specific humanoid)\n    controller.get_logger().info('Moving right arm to a waving pose.')\n    wave_positions = [0.0] * len(controller.joint_names)\n    # Assuming 'right_shoulder_joint' is at index 2, 'right_elbow_joint' at index 3\n    if len(controller.joint_names) > 3:\n        wave_positions[2] = -1.0 # Raise arm\n        wave_positions[3] = -0.5 # Bend elbow\n    controller.send_joint_command(wave_positions, time_from_start_sec=1.5)\n    rclpy.spin_once(controller, timeout_sec=2.0)\n\n    controller.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["Update ",(0,o.jsx)(n.code,{children:"setup.py"})]}),":\nAdd the entry point in ",(0,o.jsx)(n.code,{children:"~/ros2_ws/src/joint_controller_agent/setup.py"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"entry_points={\n    'console_scripts': [\n        'humanoid_joint_controller = joint_controller_agent.humanoid_joint_controller:main',\n    ],\n},\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Build and Source"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws\ncolcon build\nsource install/setup.bash\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Run Simulated Humanoid and Agent"}),":","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Terminal 1 (Start Gazebo with a humanoid robot and a joint trajectory controller, e.g., ",(0,o.jsx)(n.code,{children:"ros2 launch my_humanoid_config humanoid.launch.py"}),"):\nEnsure your humanoid model publishes joint states and has a controller subscribed to ",(0,o.jsx)(n.code,{children:"/joint_trajectory_controller/joint_trajectory"}),".\nYou might need a custom service server for ",(0,o.jsx)(n.code,{children:"/robot_home_service"})," for the ",(0,o.jsx)(n.code,{children:"call_home_service"})," to work."]}),"\n",(0,o.jsxs)(n.li,{children:["Terminal 2 (Run your Python agent):","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"ros2 run joint_controller_agent humanoid_joint_controller\n"})}),"\n"]}),"\n"]}),"\n","Observe the simulated humanoid robot moving its joints as commanded."]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Common Pitfall"}),": Incorrect joint names or an unavailable joint trajectory controller.\n",(0,o.jsx)(n.strong,{children:"Fix"}),": Verify joint names from your robot's URDF. Ensure the correct ",(0,o.jsx)(n.code,{children:"controller_manager"})," and ",(0,o.jsx)(n.code,{children:"joint_trajectory_controller"})," are loaded in your simulation."]}),"\n",(0,o.jsx)(n.h2,{id:"python-ai-for-perception-subscriberpublisher",children:"Python AI for Perception (Subscriber/Publisher)"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Create a new Python package"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws/src\nros2 pkg create --build-type ament_python simple_vision_agent --dependencies rclpy sensor_msgs cv_bridge python-opencv\ncd simple_vision_agent/simple_vision_agent\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["Create ",(0,o.jsx)(n.code,{children:"color_detector.py"})]}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom cv_bridge import CvBridge\nimport cv2\nimport numpy as np\n\nclass ColorDetector(Node):\n    def __init__(self):\n        super().__init__('color_detector')\n        self.subscription = self.create_subscription(\n            Image,\n            '/camera/image_raw', # Raw camera image topic\n            self.image_callback,\n            10)\n        self.publisher_ = self.create_publisher(Image, '/vision/segmented_image', 10)\n        self.bridge = CvBridge()\n        self.get_logger().info('Color Detector agent started, waiting for image data.')\n\n        # Define the desired color range (e.g., for detecting a green object in HSV)\n        # You might need to adjust these values based on your camera and lighting\n        self.lower_green = np.array([40, 40, 40])\n        self.upper_green = np.array([80, 255, 255])\n        self.get_logger().info(f\"Detecting color in HSV range: {self.lower_green} to {self.upper_green}\")\n\n    def image_callback(self, msg):\n        try:\n            # Convert ROS Image message to OpenCV image\n            cv_image = self.bridge.imgmsg_to_cv2(msg, 'bgr8')\n        except Exception as e:\n            self.get_logger().error(f\"Error converting image: {e}\")\n            return\n\n        # Convert BGR to HSV\n        hsv_image = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)\n\n        # Threshold the HSV image to get only green colors\n        mask = cv2.inRange(hsv_image, self.lower_green, self.upper_green)\n\n        # Bitwise-AND mask and original image\n        segmented_image = cv2.bitwise_and(cv_image, cv_image, mask=mask)\n\n        # Find contours to detect objects\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        \n        detected_objects = 0\n        for contour in contours:\n            area = cv2.contourArea(contour)\n            if area > 500: # Filter small noise\n                x, y, w, h = cv2.boundingRect(contour)\n                cv2.rectangle(segmented_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n                detected_objects += 1\n\n        if detected_objects > 0:\n            self.get_logger().info(f\"Detected {detected_objects} green objects.\")\n\n        # Convert OpenCV image back to ROS Image message and publish\n        try:\n            ros_image = self.bridge.cv2_to_imgmsg(segmented_image, 'bgr8')\n            ros_image.header = msg.header # Maintain timestamp and frame_id\n            self.publisher_.publish(ros_image)\n        except Exception as e:\n            self.get_logger().error(f\"Error converting and publishing image: {e}\")\n\ndef main(args=None):\n    rclpy.init(args=args)\n    color_detector = ColorDetector()\n    try:\n        rclpy.spin(color_detector)\n    except KeyboardInterrupt:\n        pass\n    color_detector.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["Update ",(0,o.jsx)(n.code,{children:"setup.py"})]}),":\nAdd the entry point in ",(0,o.jsx)(n.code,{children:"~/ros2_ws/src/simple_vision_agent/setup.py"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"entry_points={\n    'console_scripts': [\n        'color_detector = simple_vision_agent.color_detector:main',\n    ],\n},\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Build and Source"}),":","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws\ncolcon build\nsource install/setup.bash\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Run Camera Source and Agent"}),":","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Terminal 1 (Start a camera publisher, e.g., from a Gazebo simulation with a camera or a USB camera driver):","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# Example for a simulated camera (e.g., from a robot description)\nros2 launch your_robot_description display.launch.py\n# Or a real USB camera\nros2 run camera_ros camera_ros_driver\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Terminal 2 (Run your Python agent):","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"ros2 run simple_vision_agent color_detector\n"})}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Terminal 3 (Visualize the output):","\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"rqt_image_view /vision/segmented_image\n"})}),"\n"]}),"\n"]}),"\n","Observe the ",(0,o.jsx)(n.code,{children:"rqt_image_view"})," displaying the segmented image with detected green objects highlighted."]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Common Pitfall"}),": ",(0,o.jsx)(n.code,{children:"cv_bridge"})," not correctly installed or ",(0,o.jsx)(n.code,{children:"python-opencv"})," missing.\n",(0,o.jsx)(n.strong,{children:"Fix"}),": Ensure ",(0,o.jsx)(n.code,{children:"apt-get install ros-<ROS_DISTRO>-cv-bridge python3-opencv"})," (for Debian/Ubuntu) or ",(0,o.jsx)(n.code,{children:"pip install opencv-python"})," in your ROS 2 environment."]}),"\n",(0,o.jsx)(n.h2,{id:"common-pitfalls-and-solutions-for-python-ros-2-integration",children:"Common Pitfalls and Solutions for Python-ROS 2 Integration"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Missing Dependencies"}),": Forgetting to declare dependencies in ",(0,o.jsx)(n.code,{children:"package.xml"})," and ",(0,o.jsx)(n.code,{children:"setup.py"})," (e.g., ",(0,o.jsx)(n.code,{children:"rclpy"}),", ",(0,o.jsx)(n.code,{children:"geometry_msgs"}),", ",(0,o.jsx)(n.code,{children:"sensor_msgs"}),", ",(0,o.jsx)(n.code,{children:"nav2_msgs"}),").","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Fix"}),": Always check ",(0,o.jsx)(n.code,{children:"package.xml"})," for ",(0,o.jsx)(n.code,{children:"build_depend"}),"/",(0,o.jsx)(n.code,{children:"exec_depend"})," and ",(0,o.jsx)(n.code,{children:"setup.py"})," for ",(0,o.jsx)(n.code,{children:"install_requires"}),"."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Not Sourcing Environment"}),": ",(0,o.jsx)(n.code,{children:"ros2"})," commands or Python scripts failing because ROS 2 environment variables aren't set.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Fix"}),": ",(0,o.jsx)(n.code,{children:"source /opt/ros/<ROS_DISTRO>/setup.bash"})," and ",(0,o.jsx)(n.code,{children:"source ~/ros2_ws/install/setup.bash"})," in ",(0,o.jsx)(n.em,{children:"every new terminal"}),"."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Incorrect Message/Service/Action Types"}),": Mismatch between publisher/subscriber or client/server types.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Fix"}),": Use ",(0,o.jsx)(n.code,{children:"ros2 topic info <topic>"}),", ",(0,o.jsx)(n.code,{children:"ros2 service type <service>"}),", ",(0,o.jsx)(n.code,{children:"ros2 action info <action>"})," to verify."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Custom Interface Definition Issues"}),": Not rebuilding after changing ",(0,o.jsx)(n.code,{children:".srv"}),", ",(0,o.jsx)(n.code,{children:".action"}),", or ",(0,o.jsx)(n.code,{children:".msg"})," files, or missing ",(0,o.jsx)(n.code,{children:"rosidl_default_generators"})," dependencies.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Fix"}),": ",(0,o.jsx)(n.code,{children:"colcon build"})," and ",(0,o.jsx)(n.code,{children:"source install/setup.bash"})," after any interface changes. Ensure ",(0,o.jsx)(n.code,{children:"package.xml"})," and ",(0,o.jsx)(n.code,{children:"setup.py"})," are correctly configured for custom interfaces."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["Synchronous ",(0,o.jsx)(n.code,{children:"rclpy.spin()"})," in Long-Running Tasks"]}),": ",(0,o.jsx)(n.code,{children:"rclpy.spin(node)"})," blocks the thread, preventing other callbacks or agent logic from running.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Fix"}),": For complex agents, consider using ",(0,o.jsx)(n.code,{children:"rclpy.spin_once(node, timeout_sec=...)"})," in a loop, ",(0,o.jsx)(n.code,{children:"rclpy.callback_groups.MutuallyExclusiveCallbackGroup"}),", or dedicated threads for blocking operations to keep the main node responsive."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"student-exercises-with-hidden-solutions",children:"Student Exercises (with Hidden Solutions)"}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise 2.1: Advanced Obstacle Avoidance"}),"\nEnhance the ",(0,o.jsx)(n.code,{children:"avoidance_agent.py"})," to differentiate between obstacles on the left and right sides. If an obstacle is detected on the left, turn right. If on the right, turn left. If directly in front, stop and turn randomly."]}),"\n",(0,o.jsxs)(s,{children:[(0,o.jsx)("summary",{children:"Solution (click to expand)"}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan\nimport random\n\nclass AdvancedAvoidanceAgent(Node):\n    def __init__(self):\n        super().__init__('advanced_avoidance_agent')\n        self.publisher_ = self.create_publisher(Twist, '/cmd_vel', 10)\n        self.subscription = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.scan_callback,\n            10)\n        self.subscription\n        self.get_logger().info('Advanced Avoidance Agent has started, waiting for scan data...')\n\n        self.linear_speed = 0.2  # m/s\n        self.angular_speed = 0.5 # rad/s\n        self.threshold_distance = 0.7 # meters\n\n    def scan_callback(self, msg):\n        num_ranges = len(msg.ranges)\n        if num_ranges == 0:\n            return\n\n        # Define sectors for front, left, and right (adjust indices based on your LiDAR)\n        # Assuming 360-degree LiDAR, 0 degrees is front\n        front_left_sector = [i for i in range(315, 360)] # e.g., 315 to 359\n        front_right_sector = [i for i in range(0, 45)]   # e.g., 0 to 44\n\n        # Filter valid ranges\n        ranges = [r for r in msg.ranges if r > msg.range_min and r < msg.range_max]\n        if not ranges:\n            self.move_forward() # If no obstacles, move forward\n            return\n\n        left_obstacle = any(msg.ranges[i] < self.threshold_distance for i in front_left_sector if i < num_ranges)\n        right_obstacle = any(msg.ranges[i] < self.threshold_distance for i in front_right_sector if i < num_ranges)\n        \n        # Check if anything directly in front (a narrower band)\n        narrow_front_sector = [i for i in range(350, 360)] + [i for i in range(0, 10)]\n        front_danger = any(msg.ranges[i] < self.threshold_distance for i in narrow_front_sector if i < num_ranges)\n\n\n        twist_msg = Twist()\n        if front_danger:\n            twist_msg.linear.x = 0.0\n            twist_msg.angular.z = random.choice([-self.angular_speed, self.angular_speed]) # Random turn\n            self.get_logger().warn('Obstacle directly in front! Stopping and turning randomly.')\n        elif left_obstacle:\n            twist_msg.linear.x = 0.0\n            twist_msg.angular.z = -self.angular_speed # Turn right\n            self.get_logger().warn('Obstacle on left! Turning right.')\n        elif right_obstacle:\n            twist_msg.linear.x = 0.0\n            twist_msg.angular.z = self.angular_speed # Turn left\n            self.get_logger().warn('Obstacle on right! Turning left.')\n        else:\n            twist_msg.linear.x = self.linear_speed\n            twist_msg.angular.z = 0.0\n            self.get_logger().info('Path clear, moving forward.')\n\n        self.publisher_.publish(twist_msg)\n\n    def move_forward(self):\n        twist_msg = Twist()\n        twist_msg.linear.x = self.linear_speed\n        twist_msg.angular.z = 0.0\n        self.publisher_.publish(twist_msg)\n        self.get_logger().info('No obstacles detected, moving forward.')\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    agent = AdvancedAvoidanceAgent()\n    try:\n        rclpy.spin(agent)\n    except KeyboardInterrupt:\n        pass\n    agent.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),(0,o.jsxs)(n.p,{children:["Remember to add ",(0,o.jsx)(n.code,{children:"advanced_avoidance_agent = simple_avoidance_agent.advanced_avoidance_agent:main"})," to ",(0,o.jsx)(n.code,{children:"setup.py"})," console_scripts and rebuild."]})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise 2.2: Robot State Logger (Subscriber)"}),"\nCreate a Python agent that subscribes to the ",(0,o.jsx)(n.code,{children:"/joint_states"})," topic (message type ",(0,o.jsx)(n.code,{children:"sensor_msgs/msg/JointState"}),", which is common for humanoid robots). This agent should log the names and positions of all joints whenever an update is received."]}),"\n",(0,o.jsxs)(s,{children:[(0,o.jsx)("summary",{children:"Solution (click to expand)"}),(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"my_robot_pkg/my_robot_pkg/joint_state_logger.py"})}),":"]}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState # For joint state data\n\nclass JointStateLogger(Node):\n    def __init__(self):\n        super().__init__('joint_state_logger')\n        self.subscription = self.create_subscription(\n            JointState,\n            '/joint_states', # Common topic for joint states\n            self.joint_state_callback,\n            10)\n        self.subscription  # prevent unused variable warning\n        self.get_logger().info('Joint State Logger agent started, waiting for joint state data.')\n\n    def joint_state_callback(self, msg):\n        self.get_logger().info('--- Joint State Update ---')\n        for i, name in enumerate(msg.name):\n            position = msg.position[i] if i < len(msg.position) else 'N/A'\n            velocity = msg.velocity[i] if i < len(msg.velocity) else 'N/A'\n            effort = msg.effort[i] if i < len(msg.effort) else 'N/A'\n            self.get_logger().info(f'Joint: {name}, Position: {position:.4f}, Velocity: {velocity:.4f}, Effort: {effort:.4f}')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    joint_state_logger = JointStateLogger()\n    try:\n        rclpy.spin(joint_state_logger)\n    except KeyboardInterrupt:\n        pass\n    joint_state_logger.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),(0,o.jsxs)(n.p,{children:["Add to ",(0,o.jsx)(n.code,{children:"setup.py"})," ",(0,o.jsx)(n.code,{children:"console_scripts"}),":\n",(0,o.jsx)(n.code,{children:"'joint_state_logger = my_robot_pkg.joint_state_logger:main',"}),"\nRun with: ",(0,o.jsx)(n.code,{children:"ros2 run my_robot_pkg joint_state_logger"})," (assuming a robot publishing ",(0,o.jsx)(n.code,{children:"/joint_states"})," in simulation or real hardware)."]})]}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:"Exercise 2.3: Simple Service for Robot Status"}),"\nCreate a Python agent that provides a ROS 2 service ",(0,o.jsx)(n.code,{children:"/robot_status"})," using ",(0,o.jsx)(n.code,{children:"std_srvs/srv/Trigger"}),". When called, this service should return ",(0,o.jsx)(n.code,{children:"success=True"}),' and a message indicating the robot is "Online and ready."']}),"\n",(0,o.jsxs)(s,{children:[(0,o.jsx)("summary",{children:"Solution (click to expand)"}),(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.strong,{children:(0,o.jsx)(n.code,{children:"my_robot_pkg/my_robot_pkg/robot_status_server.py"})}),":"]}),(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom std_srvs.srv import Trigger # Standard Trigger service type\n\nclass RobotStatusService(Node):\n    def __init__(self):\n        super().__init__('robot_status_server')\n        self.srv = self.create_service(Trigger, 'robot_status', self.status_callback)\n        self.get_logger().info('Robot Status Service ready at /robot_status.')\n\n    def status_callback(self, request, response):\n        response.success = True\n        response.message = 'Robot is Online and ready.'\n        self.get_logger().info('Received status request. Responding: Online and ready.')\n        return response\n\ndef main(args=None):\n    rclpy.init(args=args)\n    robot_status_service = RobotStatusService()\n    try:\n        rclpy.spin(robot_status_service)\n    except KeyboardInterrupt:\n        pass\n    robot_status_service.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),(0,o.jsxs)(n.p,{children:["Add to ",(0,o.jsx)(n.code,{children:"setup.py"})," ",(0,o.jsx)(n.code,{children:"console_scripts"}),":\n",(0,o.jsx)(n.code,{children:"'robot_status_server = my_robot_pkg.robot_status_server:main',"}),"\nRun with: ",(0,o.jsx)(n.code,{children:"ros2 run my_robot_pkg robot_status_server"})," (in one terminal) and ",(0,o.jsx)(n.code,{children:'ros2 service call /robot_status std_srvs/srv/Trigger "{}"'})," (in another)."]})]}),"\n",(0,o.jsx)(n.h2,{id:"further-reading-and-official-resources",children:"Further Reading and Official Resources"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsxs)(n.strong,{children:["ROS 2 ",(0,o.jsx)(n.code,{children:"rclpy"})," Tutorials"]}),": The official tutorials are an excellent resource for getting started with Python in ROS 2.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html",children:"Writing a Simple Publisher and Subscriber (Python)"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Service-And-Client.html",children:"Writing a Simple Service and Client (Python)"})}),"\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Action-Server-And-Client.html",children:"Writing an Action Server and Client (Python)"})}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ROS 2 CLI Tools"}),": Essential for debugging and introspection.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Using-ROS2-cli-Tools.html",children:"Using ros2 topic CLI tools"})}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"OpenCV-Python Tutorials"}),": For deepening your understanding of computer vision tasks.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html",children:"OpenCV-Python Tutorials"})}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Nav2 Documentation"}),": For advanced navigation capabilities.","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:(0,o.jsx)(n.a,{href:"https://navigation.ros.org/",children:"Navigation2 Documentation"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["By effectively utilizing ",(0,o.jsx)(n.code,{children:"rclpy"}),", Python AI agents become powerful components within the ROS 2 ecosystem, transforming complex algorithms into real-world robotic behaviors. This modularity and rich toolset empower developers to design highly capable Physical AI systems. The next chapter will explore the critical role of URDF in defining these robotic systems."]}),"\n",(0,o.jsx)(n.hr,{}),"\n",(0,o.jsxs)(n.p,{children:[(0,o.jsx)(n.a,{href:"/docs/module-1/ros2-nodes-topics-services",children:(0,o.jsx)(n.strong,{children:"\u2190 Previous: ROS 2 Fundamentals"})})," | ",(0,o.jsx)(n.a,{href:"/docs/module-1/urdf-for-humanoids",children:(0,o.jsx)(n.strong,{children:"Next: URDF for Humanoids \u2192"})})]})]})}function g(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>i,x:()=>a});var r=s(6540);const o={},t=r.createContext(o);function i(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);